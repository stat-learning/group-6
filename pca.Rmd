---
title: "Experiment with PCA on the MNIST dataset"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(tidyr)
library(ggplot2)
library(MASS)
library(tree)
library(gbm)
library(randomForest)
library(class)
library(e1071)  
library(tidyverse)
library(caret)
library(nnet)
library(glmnet)
library(doParallel)
library(rpart)
```



```{r loading-data, include=FALSE}
# This part read idx files and store image data into train$x and 
# test$x in matrix form, store corresponding labels in train$y 
# and test$y in array form 
load_image_file <- function(filename) {
   ret = list()
    f = file(filename,'rb')
    readBin(f,'integer',n=1,size=4,endian='big')
    ret$n = readBin(f,'integer',n=1,size=4,endian='big')
    nrow = readBin(f,'integer',n=1,size=4,endian='big')
    ncol = readBin(f,'integer',n=1,size=4,endian='big')
    x = readBin(f,'integer',n=ret$n*nrow*ncol,size=1,signed=F)
    ret$x = matrix(x, ncol=nrow*ncol, byrow=T)
    close(f)
    ret
}

load_label_file <- function(filename) {
    f = file(filename,'rb')
    readBin(f,'integer',n=1,size=4,endian='big')
    n = readBin(f,'integer',n=1,size=4,endian='big')
    y = readBin(f,'integer',n=n,size=1,signed=F)
    close(f)
    y
}

train <- load_image_file("data/train-images-idx3-ubyte")
test <- load_image_file("data/t10k-images-idx3-ubyte")

train$y <- load_label_file("data/train-labels-idx1-ubyte")
test$y <- load_label_file("data/t10k-labels-idx1-ubyte")  

```


```{r data-processing, include=FALSE}
train$x <- train$x/255
test$x <- test$x/255

train_df <- data.frame(train$y, train$x) %>%
  rename(label = train.y)
test_df <- data.frame(test$y, test$x) %>%
  rename(label = test.y)

train_df$label <- as.factor(train_df$label)
test_df$label <- as.factor(test_df$label)
```





```{r pca, cache=TRUE}
# Fit PCA on the training dataset
pca <- prcomp(train_df[, -1])

# Fit PCA on the test dataset
test_pca <- predict(pca, newdata = test_df)
```

```{r pca-plot}
# Store the first two coordinates and the label in a data frame
pca_plot <- data.frame(PC1 = pca$x[, "PC1"], PC2 = pca$x[, "PC2"], 
                       label = as.factor(train_df$label))

# Plot the first two principal components using the true labels as color 
g <- ggplot(pca_plot[1:250,], aes(x = PC1, y = PC2, color = label)) + 
	ggtitle("PCA of MNIST sample") + 
	geom_text(aes(label = label)) + 
	theme(legend.position = "none")
```

```{r}
g + geom_vline(xintercept = -2.4, col = "lightblue", linetype="dashed") +
  geom_hline(yintercept = -.7, col = "tan", linetype="dashed")
```

```{r scree-plot}
d <- data.frame(PC = 1:784,
                PVE = pca$sdev^2 / sum(pca$sdev^2))

ggplot(d[1:50,], aes(x = PC, y = PVE)) +
  geom_line() + 
  geom_point() +
  theme_bw(base_size = 18)
```

We only need 20 PCs to capture 90% of the variance in our dataset.

<<<<<<< HEAD

```{r subsetting-pca}
set.seed(1)

# select the first 20 PCs for the training dataset
pca.tr <- data.frame(label = train_df[, 1], pca$x[, 1:20])
pca.tr$label <- as.factor(pca.tr$label)

pca.tst <- test_pca[, 1:20]  # select the first 20 PCs
pca.tst <- as.data.frame(pca.tst)

# select the first 20 PCs for the test dataset
pca.tst <- test_pca[, 1:20]  
pca.tst <- data.frame(label = test_df$label, pca.tst)

pca.tst$label <- as.factor(pca.tst$label)
```

## Random Forest

```{r rf-fit, cache=TRUE}

set.seed(1)

rf <- randomForest(pca.tr[, -1], pca.tr$label, ntree=500, importance = TRUE)
rf
```

```{r rf-plot, fig.align="center"}
par(mfrow = c(1,2))
varImpPlot(rf)
plot(rf)
```

```{r rf-pred}
pred.rf <- predict(rf, pca.tst, type = "class")
(conf.rf <- table(pred.rf, pca.tst$label))
```

```{r rf-mcr}
(sum(conf.rf) - sum(diag(conf.rf))) / 
  sum(conf.rf)
```

The misclassification rate is 4.89%. The pair that is most difficult to predict are 4 and 9.

## Classification Tree


```{r}
t <- rpart(label~., data=train_df, method = "class")
summary(t)
```


```{r tree-fit, cache=TRUE}
t <- tree(label ~., data = pca.tr, split = "deviance")
summary(t)
```

```{r tree-plot, fig.align="center", fig.width=10, fig.height=6}
plot(t)
text(t, pretty = 0)
```

```{r tree-pred}
pred.tree <- predict(t, newdata = pca.tst, type = "class")
(conf.tree <- table(pred.tree, test_df$label))
```

```{r tree-mcr}
(sum(conf.tree) - sum(diag(conf.tree))) / 
  sum(conf.tree)
```

4-9 is still the most difficult pair to predict, followed closely by 5-0, 7-9, 5-3, 5-8.

## Pruning tree
```{r}
t.pruned <- prune(t,  t$cptable[which.min(t$cptable[,"xerror"]),"CP"])
```

```{r pruned-tree-fit, cache=TRUE}
t.cv <- cv.tree(t)
plot(t.cv$size, t.cv$dev, type = "b", xlab = "n leaves", ylab = "error")
```

Not a good case for pruning (best n = 13 was already chosen). 

## Bagging 

```{r bagged-rf-fit, cache=TRUE}
set.seed(1)

p <- ncol(pca.tr)-1
rf.bag <- randomForest(label ~., data = pca.tr,
                  mtry = p/3, importance = TRUE) 
rf.bag
```

```{r bagged-rf-plot}
varImpPlot(rf.bag, main="Bagging")
```

```{r bagged-rf-pred}
pred.bag <- predict(rf.bag, newdata = pca.tst, type = "class")
(conf.bag <- table(pred.bag, pca.tst$label))
```

```{r bagged-rf-mse}
(sum(conf.bag) - sum(diag(conf.bag))) / 
  sum(conf.bag)
```
The misclassification rate is 5.15%.

## Boosting tree

```{r boosted-fit, cache=TRUE}
set.seed(1)

boost.mnist <- gbm(label~., data = pca.tr, 
                     distribution = "multinomial",
                     n.trees = 50, interaction.depth = 1,
                     shrinkage = 0.1)
summary(boost.mnist)
```


```{r boosted-pred}
pred.boost <- predict(boost.mnist, newdata = pca.tst, n.trees = 50)
pred.boost <- apply(pred.boost, 1, which.max) -1

(conf.boost <- table(pred.boost, pca.tst$label))
```

```{r boosted-mcr}
(sum(conf.boost) - sum(diag(conf.boost))) / 
  sum(conf.boost)
```

###Using 5-fold CV

**PCA Dataset**

```{r cache=TRUE}
boost.pca.cv <- gbm(label~., data = pca.tr, 
                distribution = "multinomial",
                n.trees = 500, 
                interaction.depth = 1,
                shrinkage = 0.1,
                cv.folds = 5
                )
summary(boost.pca.cv)
```

```{r}
print(boost.pca.cv)
```
The best number of trees chosen by the boosted model using 5-fold CV on the PCA dataset is 411.

```{r}
pred.boost.cv <- predict(boost.pca.cv, newdata = pca.tst, n.trees = 500)
pred.boost.cv <- apply(pred.boost.cv, 1, which.max) -1

(conf.boost <- table(pred.boost.cv, pca.tst$label))
```

```{r}
(sum(conf.boost) - sum(diag(conf.boost))) / 
  sum(conf.boost)
```

The misclassification rate is 9.81. 4-9 is still the most difficult pair to predict.

**Original Dataset**

```{r warning=FALSE, message=FALSE, cache=TRUE}
boost.og.cv <- gbm(label~., data = train_df, 
                distribution = "multinomial",
                n.trees = 500, 
                interaction.depth = 1,
                shrinkage = 0.1,
                cv.folds = 5)
summary(boost.og.cv)
```

```{r}
print(boost.og.cv)
```

The best number of trees chosen by the boosted model using 5-fold CV on the PCA dataset is 454.

```{r}
pred.boost.og.cv <- predict(boost.og.cv, newdata = test_df, n.trees=500)
pred.boost.og.cv <- apply(pred.boost.og.cv, 1, which.max) -1

(conf.boost <- table(pred.boost.og.cv, test_df$label))
```

```{r}
(sum(conf.boost) - sum(diag(conf.boost))) / 
  sum(conf.boost)
```

The misclassification rate is 8.38. 4-9 is still the most difficult pair to predict.


## Logistic Regression 
```{r}
lambdas <- seq(2,0,length = 20)
registerDoParallel()
train_df
```
```{r, cache=TRUE}
# basic logistic regression without penalization 
raw_log <- multinom(label~., data=train_df, MaxNWts = 10000)
pca_log <- multinom(label~., data=pca.tr)
```
```{r}
raw_log_pred <- predict(raw_log, test_df, type="class")
pca_log_pred <- predict(pca_log, pca.tst, type="class")
raw_log_MSE <- mean(raw_log_pred!=test$y)
pca_log_MSE <- mean(pca_log_pred!=pca.tst[,21])
```


```{r, cache=TRUE}
# Ridge and Lasso for raw dataset
raw_log_ridge <- cv.glmnet(train$x, train$y, family = "multinomial", parallel= TRUE, alpha = 0)
raw_log_lasso <- cv.glmnet(train$x, train$y, family = "multinomial", parallel= TRUE, alpha = 1)
```
```{r, cache=TRUE}
plot(raw_log_ridge)
plot(raw_log_lasso)
raw_ridge_MSE = rep(NA,length = length(raw_log_ridge$lambda))
for (i in 1:length(raw_log_ridge$lambda)){
  p = predict(raw_log_ridge, s = raw_log_ridge$lambda[i], newx = test$x, type = "class")
  raw_ridge_MSE[i] =  mean(p != test$y)
}
raw_ridge_MSE= min(raw_ridge_MSE)
raw_lasso_MSE = rep(NA,length = length(raw_log_lasso$lambda))
for (i in 1:length(raw_log_lasso$lambda)){
  p = predict(raw_log_lasso, s = raw_log_lasso$lambda[i], newx = test$x, type = "class")
  raw_lasso_MSE[i] =  mean(p != test$y)
}
raw_lasso_MSE= min(raw_lasso_MSE)
```



```{r cache=TRUE}
# Ridge and Lasso for pca dataset
pca_log_ridge <- cv.glmnet(as.matrix(pca.tr[,-1]), pca.tr[,1], family = "multinomial", parallel= TRUE, alpha = 0)
pca_log_lasso <- cv.glmnet(as.matrix(pca.tr[,-1]), pca.tr[,1], family = "multinomial", parallel= TRUE, alpha = 1)
```
```{r, cache=TRUE}
plot(pca_log_ridge)
plot(pca_log_lasso)
pca_ridge_MSE = rep(NA,length = length(pca_log_ridge$lambda))
for (i in 1:length(pca_log_ridge$lambda)){
  p = predict(pca_log_ridge, s = pca_log_ridge$lambda[i], newx = as.matrix(pca.tst[,-21]), type = "class")
  pca_ridge_MSE[i] =  mean(p != pca.tst[,21])
}
pca_ridge_MSE= min(pca_ridge_MSE)

pca_lasso_MSE = rep(NA,length = length(pca_log_lasso$lambda))
for (i in 1:length(pca_log_lasso$lambda)){
  p = predict(pca_log_lasso, s = pca_log_lasso$lambda[i], newx = as.matrix(pca.tst[,-21]), type = "class")
  pca_lasso_MSE[i] =  mean(p != pca.tst[,21])
  pca_lasso_MSE= min(pca_lasso_MSE)
```

```{r}
par(mfrow=c(2,2))
par(mar=c(0.1,0.1,0.1,0.1))
plot(raw_log_lasso)
plot(raw_log_ridge)
plot(pca_log_lasso)
plot(pca_log_ridge)
```



```{r}
# Summary of MSEs
c(raw_log_MSE, raw_ridge_MSE, raw_lasso_MSE)
c(pca_log_MSE, pca_ridge_MSE, pca_lasso_MSE)
```


## KNN 
```{r, cache=TRUE}
# KNN of raw data
knn.pred_raw <- knn(train_df[,-1], test_df[,-1],train_df[,1], k =5) # use CV the best k is 5 
raw_knn_MSE <- 1 - mean(knn.pred_raw == test_df[,1])
raw_knn_table <- table(knn.pred_raw, test_df[,1])
raw_knn_table
raw_knn_MSE
```

```{r, cache=TRUE}
# use cv to find best k 
knn_err <- rep(0,10)
for (i in 1:10){
  knn.cv <- knn.cv(pca.tr[,-1], pca.tr[,1], k = i)
  knn_err[i] <- mean(knn.cv != pca.tr[,1])
}
plot(knn_err, xlab = "k", ylab = "MCR")
```

```{r, cache=TRUE}
# KNN of pca data
knn.pred <- knn(pca.tr[,-1], pca.tst[, -21], pca.tr[,1], k =5) # use CV the bestg k is 5 
pca_knn_MSE <- 1 - mean(knn.pred == pca.tst[,21])
table(knn.pred, pca.tst[,21])
pca_knn_MSE
```
Clearly, with KNN method, the misclassifcation rate is 3.01%. 4-9 pair is the hardest one to predict.


## SVM
```{r}
#SVM for raw data 
# This part trains for too long time, we cancel SVM for raw data 
raw_svm_cv <- tune(svm,label~.,data=train_df ,kernel="polynomial",degree = 4,  ranges=list(cost=c(0.001, 0.01, 0.1, 1,5,10,100) ))
raw_svm <- svm(label~., data = train_df, method="C-classification", kernal="radial", gamma= 0.1, cost=10)
raw_svm_pred <- predict(raw_svm, test_df)
raw_table_svm <- table(raw_svm_pred, test$y)
raw_svm_MSE <- 1- mean(raw_svm_pred == test$y)
raw_svm_MSE
raw_table_svm
```


```{r}
#SVM for pca data 
pca_svm <- svm(label~., data = pca.tr, method="C-classification", kernal="radial", gamma= 0.1, cost=10)
pca_svm_pred <- predict(pca_svm, pca.tst)
raw_table_svm <- table(pca_svm_pred, pca.tst[,21])
pca_svm_MSE <- 1- mean(pca_svm_pred == pca.tst[,21])
pca_svm_MSE
raw_table_svm
plot(pca_svm, data = pca.tr[1:250,], PC2 ~ PC1, fill = T)

```

Clearly, with SVM method, the misclassifcation rate is 2.17%. 4-9 pair is the hardest one to predict.